{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rosc</th>\n",
       "      <th>ohca</th>\n",
       "      <th>shockable_rhythm</th>\n",
       "      <th>ttm</th>\n",
       "      <th>outcome</th>\n",
       "      <th>cpc</th>\n",
       "      <th>rosc_missing</th>\n",
       "      <th>shockable_rhythm_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No TTM</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hospital   age     sex  rosc   ohca shockable_rhythm     ttm outcome  cpc  \\\n",
       "0        A  53.0    Male  -1.0   True             True    33.0    Good    1   \n",
       "1        F  85.0  Female   7.0  False            False  No TTM    Good    1   \n",
       "2        A  48.0    Male  -1.0   True             True    36.0    Good    1   \n",
       "3        A  45.0    Male  -1.0   True             True    33.0    Good    1   \n",
       "4        D  51.0    Male  24.0   True             True    33.0    Good    1   \n",
       "\n",
       "   rosc_missing  shockable_rhythm_missing  \n",
       "0             1                         0  \n",
       "1             0                         0  \n",
       "2             1                         0  \n",
       "3             1                         0  \n",
       "4             0                         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/processed_patient_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "0    382\n",
      "1    225\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['outcome'] = data['outcome'].map({'Good': 1, 'Poor': 0})\n",
    "print(data['outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital : ['A' 'F' 'D' 'E' 'B']\n",
      "age : [53.         85.         48.         45.         51.         73.\n",
      " 39.         56.         41.         62.         55.         46.\n",
      " 68.         54.         64.         67.         66.         79.\n",
      " 71.         50.         78.         59.         52.         40.\n",
      " 70.         82.         80.         69.         72.         83.\n",
      " 88.         57.         74.         36.         34.         60.\n",
      " 44.         65.         63.         26.         61.         76.\n",
      " 47.         75.         29.         42.         20.         32.\n",
      " 90.         38.         81.         31.         89.         19.\n",
      " 23.         58.         35.         21.         43.         27.\n",
      " 25.         49.         37.         30.         77.         61.16831683\n",
      " 84.         86.         17.         16.         87.         22.\n",
      " 28.        ]\n",
      "sex : ['Male' 'Female']\n",
      "rosc : [ -1.   7.  24.  20.   3.  37.  40.  60.  30.  15.   5.  18.  25.  10.\n",
      "  70.  17.  50.  36.  27.  90.   2.  11.  34.  22.  33.  55.  16.  13.\n",
      "  21.  12.  26.   4.   8.  19.   9.  35.  29.  42.  52.  14.  32.  96.\n",
      "  63.  45.  44.   1.   6.  67. 100.  62.  95.  80.  54. 111.  47.  98.\n",
      "  38.]\n",
      "ohca : ['True' 'False' 'Unknown']\n",
      "shockable_rhythm : ['True' 'False' 'Unknown']\n",
      "ttm : ['33.0' 'No TTM' '36.0']\n",
      "outcome : [1 0]\n",
      "cpc : [1 2 5 3 4]\n",
      "rosc_missing : [1 0]\n",
      "shockable_rhythm_missing : [0 1]\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns:\n",
    "    unique_values = data[column].unique()\n",
    "    print(f\"{column} : {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['ohca'] != 'Unknown') & (data['shockable_rhythm'] != 'Unknown')]\n",
    "data.drop(columns=['cpc','shockable_rhythm_missing','rosc_missing'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rosc</th>\n",
       "      <th>ohca</th>\n",
       "      <th>shockable_rhythm</th>\n",
       "      <th>ttm</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No TTM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hospital   age     sex  rosc   ohca shockable_rhythm     ttm  outcome\n",
       "0        A  53.0    Male  -1.0   True             True    33.0        1\n",
       "1        F  85.0  Female   7.0  False            False  No TTM        1\n",
       "2        A  48.0    Male  -1.0   True             True    36.0        1\n",
       "3        A  45.0    Male  -1.0   True             True    33.0        1\n",
       "4        D  51.0    Male  24.0   True             True    33.0        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rosc</th>\n",
       "      <th>ohca</th>\n",
       "      <th>shockable_rhythm</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ttm_33.0</th>\n",
       "      <th>ttm_36.0</th>\n",
       "      <th>ttm_No TTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hospital   age     sex  rosc   ohca shockable_rhythm  outcome  ttm_33.0  \\\n",
       "0        A  53.0    Male  -1.0   True             True        1      True   \n",
       "1        F  85.0  Female   7.0  False            False        1     False   \n",
       "2        A  48.0    Male  -1.0   True             True        1     False   \n",
       "3        A  45.0    Male  -1.0   True             True        1      True   \n",
       "4        D  51.0    Male  24.0   True             True        1      True   \n",
       "\n",
       "   ttm_36.0  ttm_No TTM  \n",
       "0     False       False  \n",
       "1     False        True  \n",
       "2      True       False  \n",
       "3     False       False  \n",
       "4     False       False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use One-Hot Encoding\n",
    "# in the case of TTM values 33, 36, and no TTM, \n",
    "# the encoding maintains their distinctiveness without suggesting any ranking.\n",
    "ttm_dummies = pd.get_dummies(data['ttm'], prefix='ttm', drop_first=False)\n",
    "\n",
    "data = pd.concat([data, ttm_dummies], axis=1)\n",
    "\n",
    "data.drop(columns=['ttm'], inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86188\\AppData\\Local\\Temp\\ipykernel_25540\\3721969630.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[['shockable_rhythm', 'ohca']] = df[['shockable_rhythm', 'ohca']].replace({'True': 1, 'False': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rosc</th>\n",
       "      <th>ohca</th>\n",
       "      <th>shockable_rhythm</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ttm_33.0</th>\n",
       "      <th>ttm_36.0</th>\n",
       "      <th>ttm_No TTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hospital   age  sex  rosc  ohca  shockable_rhythm  outcome  ttm_33.0  \\\n",
       "0         0  53.0    1  -1.0     1                 1        1         1   \n",
       "1         4  85.0    0   7.0     0                 0        1         0   \n",
       "2         0  48.0    1  -1.0     1                 1        1         0   \n",
       "3         0  45.0    1  -1.0     1                 1        1         1   \n",
       "4         2  51.0    1  24.0     1                 1        1         1   \n",
       "\n",
       "   ttm_36.0  ttm_No TTM  \n",
       "0         0           0  \n",
       "1         0           1  \n",
       "2         1           0  \n",
       "3         0           0  \n",
       "4         0           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[['shockable_rhythm', 'ohca']] = df[['shockable_rhythm', 'ohca']].replace({'True': 1, 'False': 0})\n",
    "df['sex'] = df['sex'].map({'Male': 1, 'Female': 0})\n",
    "df[['ttm_33.0', 'ttm_36.0', 'ttm_No TTM']] = df[['ttm_33.0', 'ttm_36.0', 'ttm_No TTM']].astype(int)\n",
    "\n",
    "le_hospital = LabelEncoder()\n",
    "df['hospital'] = le_hospital.fit_transform(df['hospital'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital : [0 4 2 3 1]\n",
      "age : [53.         85.         48.         45.         51.         73.\n",
      " 39.         56.         41.         62.         55.         46.\n",
      " 68.         54.         64.         67.         66.         71.\n",
      " 50.         78.         59.         40.         70.         82.\n",
      " 52.         69.         72.         83.         88.         57.\n",
      " 74.         36.         34.         60.         44.         63.\n",
      " 26.         61.         76.         47.         79.         42.\n",
      " 20.         75.         32.         90.         38.         81.\n",
      " 31.         89.         19.         23.         58.         35.\n",
      " 21.         43.         27.         25.         49.         37.\n",
      " 65.         30.         77.         61.16831683 80.         84.\n",
      " 86.         17.         29.         16.         87.         22.\n",
      " 28.        ]\n",
      "sex : [1 0]\n",
      "rosc : [ -1.   7.  24.  20.   3.  37.  40.  60.  30.  15.   5.  18.  25.  10.\n",
      "  70.  17.  50.  36.  27.  90.   2.  11.  34.  22.  33.  55.  16.  13.\n",
      "  21.  12.  26.   4.   8.  19.   9.  35.  29.  42.  52.  14.  32.  96.\n",
      "  63.  45.  44.   1.   6.  67. 100.  62.  95.  80.  54. 111.  47.  98.\n",
      "  38.]\n",
      "ohca : [1 0]\n",
      "shockable_rhythm : [1 0]\n",
      "outcome : [1 0]\n",
      "ttm_33.0 : [1 0]\n",
      "ttm_36.0 : [0 1]\n",
      "ttm_No TTM : [0 1]\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"{column} : {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ohca'] = df['ohca'].astype(int)\n",
    "df['shockable_rhythm'] = df['shockable_rhythm'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hospital   age  sex  rosc  ohca  shockable_rhythm  ttm_33.0  ttm_36.0  \\\n",
      "0         0  53.0    1  -1.0     1                 1         1         0   \n",
      "1         4  85.0    0   7.0     0                 0         0         0   \n",
      "2         0  48.0    1  -1.0     1                 1         0         1   \n",
      "3         0  45.0    1  -1.0     1                 1         1         0   \n",
      "4         2  51.0    1  24.0     1                 1         1         0   \n",
      "\n",
      "   ttm_No TTM  \n",
      "0           0  \n",
      "1           1  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features = df.columns.difference(['outcome'], sort=False)\n",
    "X = df[features]\n",
    "y = df['outcome']\n",
    "print(X.head(5))\n",
    "print(y.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\APP\\python3.12\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.62661474        nan 0.64199935 0.67520286 0.62661474        nan\n",
      " 0.64199935 0.67520286 0.62661474        nan 0.64199935 0.67520286\n",
      " 0.6802986         nan 0.67010711 0.66234989 0.6802986         nan\n",
      " 0.67010711 0.66491399 0.68286271        nan 0.67010711 0.66491399\n",
      " 0.68795846        nan 0.6751704  0.6777345  0.68795846        nan\n",
      " 0.6751704  0.6777345  0.68795846        nan 0.6751704  0.6777345\n",
      " 0.6726063         nan 0.6751704  0.67770204 0.6726063         nan\n",
      " 0.6751704  0.6751704  0.6726063         nan 0.6751704  0.6751704\n",
      " 0.67770204        nan 0.67770204 0.67770204 0.6751704         nan\n",
      " 0.67770204 0.6751704  0.6751704         nan 0.67770204 0.6751704 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'penalty': ['l1', 'l2'],  \n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "logistic_grid = GridSearchCV(logistic, logistic_param_grid, cv=5)\n",
    "logistic_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression parameters:\", logistic_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "svm_grid = GridSearchCV(svm, svm_param_grid, cv=5)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVM parameters:\", svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(xgb, xgb_param_grid, cv=5)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best XGBoost parameters:\", xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\APP\\python3.12\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5388 - loss: 0.8845 - val_accuracy: 0.7089 - val_loss: 0.5720\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.6580 - val_accuracy: 0.7468 - val_loss: 0.5986\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 0.7020 - val_accuracy: 0.4430 - val_loss: 0.8278\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6510 - loss: 0.6255 - val_accuracy: 0.4937 - val_loss: 0.7211\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5709 - loss: 0.6716 - val_accuracy: 0.5063 - val_loss: 0.8065\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6624 - loss: 0.6176 - val_accuracy: 0.5696 - val_loss: 0.6579\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6751 - loss: 0.6193 - val_accuracy: 0.7215 - val_loss: 0.5594\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6418 - loss: 0.6328 - val_accuracy: 0.5063 - val_loss: 0.7689\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 0.7009 - val_accuracy: 0.5696 - val_loss: 0.6525\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.6141 - val_accuracy: 0.7215 - val_loss: 0.5441\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6294 - loss: 0.6303 - val_accuracy: 0.5696 - val_loss: 0.6627\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 0.6005 - val_accuracy: 0.6709 - val_loss: 0.5945\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.5825 - val_accuracy: 0.5316 - val_loss: 0.7001\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.6505 - val_accuracy: 0.7975 - val_loss: 0.5526\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.5891 - val_accuracy: 0.4684 - val_loss: 0.7625\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 0.5845 - val_accuracy: 0.6835 - val_loss: 0.5593\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6921 - loss: 0.5841 - val_accuracy: 0.6456 - val_loss: 0.5895\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7630 - loss: 0.5522 - val_accuracy: 0.7848 - val_loss: 0.5500\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7098 - loss: 0.5525 - val_accuracy: 0.7342 - val_loss: 0.5573\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6841 - loss: 0.5941 - val_accuracy: 0.6203 - val_loss: 0.6309\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7090 - loss: 0.5417 - val_accuracy: 0.6835 - val_loss: 0.5632\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.5438 - val_accuracy: 0.7468 - val_loss: 0.5391\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.6045 - val_accuracy: 0.7468 - val_loss: 0.5391\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6848 - loss: 0.5823 - val_accuracy: 0.7215 - val_loss: 0.6334\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6393 - loss: 0.6373 - val_accuracy: 0.5949 - val_loss: 0.6741\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7538 - loss: 0.5449 - val_accuracy: 0.6076 - val_loss: 0.6411\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.5512 - val_accuracy: 0.5316 - val_loss: 0.7686\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6824 - loss: 0.6270 - val_accuracy: 0.7595 - val_loss: 0.5405\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6745 - loss: 0.5881 - val_accuracy: 0.7342 - val_loss: 0.5509\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6640 - loss: 0.6143 - val_accuracy: 0.6076 - val_loss: 0.6598\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.5622 - val_accuracy: 0.6835 - val_loss: 0.5610\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6982 - loss: 0.5808 - val_accuracy: 0.7468 - val_loss: 0.5617\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.5896 - val_accuracy: 0.6329 - val_loss: 0.6042\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.5712 - val_accuracy: 0.6076 - val_loss: 0.6539\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.5376 - val_accuracy: 0.6582 - val_loss: 0.5625\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.5413 - val_accuracy: 0.5949 - val_loss: 0.7190\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5631 - val_accuracy: 0.6076 - val_loss: 0.6821\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7177 - loss: 0.5609 - val_accuracy: 0.7595 - val_loss: 0.5480\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5173 - val_accuracy: 0.7342 - val_loss: 0.5449\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.5508 - val_accuracy: 0.6329 - val_loss: 0.5827\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6762 - loss: 0.5551 - val_accuracy: 0.6456 - val_loss: 0.5600\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7068 - loss: 0.5402 - val_accuracy: 0.7468 - val_loss: 0.5772\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.6002 - val_accuracy: 0.7342 - val_loss: 0.5525\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5371 - val_accuracy: 0.7342 - val_loss: 0.5488\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.5188 - val_accuracy: 0.6329 - val_loss: 0.6421\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7672 - loss: 0.5162 - val_accuracy: 0.6203 - val_loss: 0.5839\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7122 - loss: 0.5463 - val_accuracy: 0.6329 - val_loss: 0.5884\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7147 - loss: 0.5500 - val_accuracy: 0.6203 - val_loss: 0.7351\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6990 - loss: 0.5840 - val_accuracy: 0.6329 - val_loss: 0.5718\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6534 - loss: 0.6871 - val_accuracy: 0.6456 - val_loss: 0.5642\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6817 - loss: 0.5654 - val_accuracy: 0.6456 - val_loss: 0.5795\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5337 - val_accuracy: 0.7595 - val_loss: 0.5544\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6777 - loss: 0.5500 - val_accuracy: 0.6203 - val_loss: 0.6243\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.5972 - val_accuracy: 0.6203 - val_loss: 0.6431\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5403 - val_accuracy: 0.6329 - val_loss: 0.5860\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7041 - loss: 0.5367 - val_accuracy: 0.6709 - val_loss: 0.5562\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.5076 - val_accuracy: 0.6329 - val_loss: 0.6314\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.5407 - val_accuracy: 0.7342 - val_loss: 0.5581\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6609 - loss: 0.6470 - val_accuracy: 0.6329 - val_loss: 0.5812\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7544 - loss: 0.4993 - val_accuracy: 0.6203 - val_loss: 0.6717\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 0.5427 - val_accuracy: 0.6329 - val_loss: 0.5819\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7576 - loss: 0.5433 - val_accuracy: 0.6329 - val_loss: 0.6548\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7056 - loss: 0.5507 - val_accuracy: 0.6329 - val_loss: 0.5960\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5191 - val_accuracy: 0.5949 - val_loss: 0.7759\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.5836 - val_accuracy: 0.6709 - val_loss: 0.5638\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.5146 - val_accuracy: 0.6456 - val_loss: 0.5576\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7071 - loss: 0.5567 - val_accuracy: 0.6329 - val_loss: 0.6640\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7011 - loss: 0.5662 - val_accuracy: 0.6456 - val_loss: 0.5987\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5174 - val_accuracy: 0.6329 - val_loss: 0.5745\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7094 - loss: 0.5530 - val_accuracy: 0.6329 - val_loss: 0.5756\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.4826 - val_accuracy: 0.6203 - val_loss: 0.5668\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6806 - loss: 0.6040 - val_accuracy: 0.6329 - val_loss: 0.5697\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7480 - loss: 0.5196 - val_accuracy: 0.6456 - val_loss: 0.6193\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5465 - val_accuracy: 0.6456 - val_loss: 0.6448\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.5704 - val_accuracy: 0.7722 - val_loss: 0.5541\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6853 - loss: 0.5610 - val_accuracy: 0.6329 - val_loss: 0.5839\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4575 - val_accuracy: 0.6076 - val_loss: 0.6923\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5502 - val_accuracy: 0.5949 - val_loss: 0.7499\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6912 - loss: 0.6433 - val_accuracy: 0.6329 - val_loss: 0.5822\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5127 - val_accuracy: 0.6329 - val_loss: 0.5746\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.5184 - val_accuracy: 0.7215 - val_loss: 0.5532\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.5152 - val_accuracy: 0.5823 - val_loss: 0.7811\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.6704 - val_accuracy: 0.6962 - val_loss: 0.5760\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5280 - val_accuracy: 0.7342 - val_loss: 0.5703\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6612 - loss: 0.5954 - val_accuracy: 0.6835 - val_loss: 0.5619\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6882 - loss: 0.5870 - val_accuracy: 0.6709 - val_loss: 0.5610\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7187 - loss: 0.5569 - val_accuracy: 0.7595 - val_loss: 0.5565\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6658 - loss: 0.5807 - val_accuracy: 0.6582 - val_loss: 0.5643\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.5059 - val_accuracy: 0.7215 - val_loss: 0.5561\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.5305 - val_accuracy: 0.6456 - val_loss: 0.5722\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7022 - loss: 0.6154 - val_accuracy: 0.7342 - val_loss: 0.5667\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7091 - loss: 0.5136 - val_accuracy: 0.6456 - val_loss: 0.6305\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.4940 - val_accuracy: 0.6582 - val_loss: 0.6459\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7482 - loss: 0.5367 - val_accuracy: 0.6456 - val_loss: 0.6593\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.5083 - val_accuracy: 0.7468 - val_loss: 0.5551\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.5122 - val_accuracy: 0.6709 - val_loss: 0.5708\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6689 - loss: 0.5698 - val_accuracy: 0.6329 - val_loss: 0.5921\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5151 - val_accuracy: 0.6456 - val_loss: 0.5792\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.5346 - val_accuracy: 0.6329 - val_loss: 0.5763\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7473 - loss: 0.5416 - val_accuracy: 0.6203 - val_loss: 0.5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c01f715f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_ann():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "ann_model = create_ann()\n",
    "\n",
    "ann_model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       105\n",
      "           1       0.66      0.60      0.63        63\n",
      "\n",
      "    accuracy                           0.73       168\n",
      "   macro avg       0.71      0.71      0.71       168\n",
      "weighted avg       0.73      0.73      0.73       168\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72       105\n",
      "           1       0.56      0.75      0.64        63\n",
      "\n",
      "    accuracy                           0.68       168\n",
      "   macro avg       0.68      0.70      0.68       168\n",
      "weighted avg       0.72      0.68      0.69       168\n",
      "\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81       105\n",
      "           1       0.72      0.49      0.58        63\n",
      "\n",
      "    accuracy                           0.74       168\n",
      "   macro avg       0.73      0.69      0.70       168\n",
      "weighted avg       0.74      0.74      0.72       168\n",
      "\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "ANN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       105\n",
      "           1       0.61      0.68      0.64        63\n",
      "\n",
      "    accuracy                           0.71       168\n",
      "   macro avg       0.70      0.71      0.70       168\n",
      "weighted avg       0.72      0.71      0.72       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_logistic = logistic_grid.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_logistic))\n",
    "\n",
    "y_pred_svm = svm_grid.predict(X_test)\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "y_pred_xgb = xgb_grid.predict(X_test)\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "y_pred_ann = (ann_model.predict(X_test) > 0.5).astype(\"int32\") \n",
    "print(\"ANN Classification Report:\\n\", classification_report(y_test, y_pred_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Summary\n",
    "\n",
    "#### 1. Logistic Regression\n",
    "- **Precision**: Moderate, with class 0 at **0.76** and class 1 at **0.58**\n",
    "- **Recall**: Balanced recall for both classes, **0.75** for class 0 and **0.60** for class 1\n",
    "- **Overall Accuracy**: **69%** (second lowest)\n",
    "- **Suitability**: Provides balanced performance, suitable for cases needing consistent detection across classes, though precision for class 1 could be improved.\n",
    "\n",
    "#### 2. SVM (Support Vector Machine)\n",
    "- **Precision**: Higher for class 0 than class 1 (**0.81** vs **0.56**)\n",
    "- **Recall**: Higher for class 1 (**0.75**), indicating a tendency to identify class 1 more often\n",
    "- **Overall Accuracy**: **68%** (the lowest among models)\n",
    "- **Suitability**: Suitable for cases where identifying class 1 is prioritized, though precision for class 1 could be improved.\n",
    "\n",
    "#### 3. XGBoost\n",
    "- **Precision & Recall**: Strong performance for class 0 (**0.74** precision, **0.89** recall), while recall for class 1 is lower (**0.49**)\n",
    "- **Overall Accuracy**: **74%** (the highest among models)\n",
    "- **Suitability**: Effective for identifying class 0, but may need tuning to improve recall for class 1.\n",
    "\n",
    "#### 4. ANN (Artificial Neural Network)\n",
    "- **Balanced Performance**: Moderate precision and recall for both classes; **0.81** precision for class 0 and **0.72** for class 1\n",
    "- **Overall Accuracy**: **70%** (mid-range performance)\n",
    "- **Suitability**: Useful for scenarios requiring balanced prediction but could benefit from additional tuning to improve accuracy.\n",
    "\n",
    "Each model has distinct strengths:\n",
    "- **Logistic Regression** offers stable but moderate performance across both classes.\n",
    "- **SVM** is best for prioritizing recall in class 1.\n",
    "- **XGBoost** performs strongly for class 0 but could benefit from tuning for class 1.\n",
    "- **ANN** is balanced but could further improve with hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero variance columns: []\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535426\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  391\n",
      "Model:                          Logit   Df Residuals:                      382\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 29 Oct 2024   Pseudo R-squ.:                  0.1897\n",
      "Time:                        00:24:06   Log-Likelihood:                -209.35\n",
      "converged:                       True   LL-Null:                       -258.35\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.095e-17\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                0.7617        nan        nan        nan         nan         nan\n",
      "hospital            -0.0227      0.128     -0.178      0.859      -0.273       0.228\n",
      "age                 -0.0371      0.008     -4.400      0.000      -0.054      -0.021\n",
      "sex                  0.0873      0.263      0.332      0.740      -0.428       0.602\n",
      "rosc                -0.0197      0.008     -2.442      0.015      -0.035      -0.004\n",
      "ohca                -0.5628      0.307     -1.832      0.067      -1.165       0.039\n",
      "shockable_rhythm     2.0180      0.280      7.211      0.000       1.469       2.566\n",
      "ttm_33.0             0.4038        nan        nan        nan         nan         nan\n",
      "ttm_36.0            -0.0094        nan        nan        nan         nan         nan\n",
      "ttm_No TTM           0.3673        nan        nan        nan         nan         nan\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Convert X_train from a NumPy array to a DataFrame and specify column names\n",
    "# Ensure these column names match those in your original data\n",
    "column_names = ['hospital', 'age', 'sex', 'rosc', 'ohca', 'shockable_rhythm', 'ttm_33.0', \n",
    "                'ttm_36.0', 'ttm_No TTM']\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train, columns=column_names)  # Specify column names\n",
    "\n",
    "# Check for zero-variance columns\n",
    "zero_variance_columns = [col for col in X_train_df.columns if X_train_df[col].nunique() == 1]\n",
    "print(\"Zero variance columns:\", zero_variance_columns)\n",
    "\n",
    "# Remove zero-variance columns if they exist\n",
    "X_train_df = X_train_df.drop(columns=zero_variance_columns)\n",
    "\n",
    "# Re-attempt fitting the logistic regression model\n",
    "X_train_with_const = sm.add_constant(X_train_df)  # Add constant term\n",
    "logit_model = sm.Logit(y_train, X_train_with_const).fit()  # Fit the model\n",
    "print(logit_model.summary())  # Output the summary of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import plotly.express as px\n",
    "\n",
    "sample_size = 100\n",
    "X_train_sample = X_train.sample(n=100, random_state=42)  # Random sampling\n",
    "y_train_sample = y_train.loc[X_train_sample.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_svm_model = svm_grid.best_estimator_\n",
    "\n",
    "explainer = shap.Explainer(best_svm_model, X_train_sample)\n",
    "shap_values = explainer(X_train_sample)\n",
    "\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Mean SHAP Value=%{marker.color}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0.5267598,
           0.23543465,
           0.10032657,
           0.032067213,
           0.017232625,
           0.010023125,
           0.0034127035,
           0.002352506,
           0
          ],
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          0.5267598,
          0.23543465,
          0.10032657,
          0.032067213,
          0.017232625,
          0.010023125,
          0.0034127035,
          0.002352506,
          0
         ],
         "xaxis": "x",
         "y": [
          "shockable_rhythm",
          "age",
          "rosc",
          "ohca",
          "hospital",
          "sex",
          "ttm_No TTM",
          "ttm_33.0",
          "ttm_36.0"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Mean SHAP Value"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Mean SHAP Value by Feature"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Mean SHAP Value"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Feature"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_xgb_model = xgb_grid.best_estimator_\n",
    "\n",
    "explainer = shap.TreeExplainer(best_xgb_model)\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_sample)\n",
    "# Create an Explanation object, including feature names\n",
    "explainer_values = shap.Explanation(\n",
    "    values=shap_values,\n",
    "    base_values=explainer.expected_value,\n",
    "    data=X_train_sample,\n",
    "    feature_names=X_train_sample.columns \n",
    ")\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_train_sample.columns)\n",
    "\n",
    "# Calculate the mean absolute SHAP value for each feature\n",
    "mean_shap_values = shap_df.abs().mean().sort_values(ascending=False)\n",
    "mean_shap_df = mean_shap_values.reset_index()\n",
    "mean_shap_df.columns = ['Feature', 'Mean SHAP Value']\n",
    "fig = px.bar(\n",
    "    mean_shap_df,\n",
    "    x='Mean SHAP Value',\n",
    "    y='Feature',\n",
    "    title='Mean SHAP Value by Feature',\n",
    "    orientation='h',  \n",
    "    labels={'Mean SHAP Value': 'Mean SHAP Value', 'Feature': 'Feature'},\n",
    "    color='Mean SHAP Value',  \n",
    "    color_continuous_scale=px.colors.sequential.Plasma  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
